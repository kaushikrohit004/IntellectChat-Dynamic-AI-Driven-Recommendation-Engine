{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7sKGM2tOikK"
      },
      "source": [
        "## Installing / importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3UWn0j84RvI"
      },
      "outputs": [],
      "source": [
        "# !pip3 install surprise whoosh sentence_transformers recommenders tf-slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gpakRw3Gs3L"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy import stats\n",
        "from sklearn.ensemble import GradientBoostingRegressor as GBRT\n",
        "from sklearn.ensemble import RandomForestRegressor as RFR\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "\n",
        "from surprise import SVD, Dataset, KNNBaseline, Reader, SVDpp\n",
        "from tqdm import tqdm\n",
        "from tqdm.auto import tqdm as tqdm_pandas\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from tqdm import trange, tqdm\n",
        "from whoosh import fields, index, qparser, scoring\n",
        "\n",
        "from recommenders.models.ncf.ncf_singlenode import NCF\n",
        "from recommenders.models.ncf.dataset import Dataset as NCFDataset\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnOkaub7pBh9"
      },
      "source": [
        "## Mount google drive and set path for dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5SjM9rQ3ZNS"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "DATAPATH = '/common/users/jrp328/data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XhpSV0Kj_0v"
      },
      "source": [
        "## True to train models\n",
        "## False to use preloaded models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHREM7yEiZ_Y"
      },
      "outputs": [],
      "source": [
        "REGENERATE = True\n",
        "CREATE_INDEX = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlRFeQK4j4BA"
      },
      "source": [
        "## Setting up schema and whoosh parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y75WT3cij2uO"
      },
      "outputs": [],
      "source": [
        "schema = fields.Schema(movie_id=fields.KEYWORD(stored=True, scorable=True),\n",
        "                       critic_id=fields.KEYWORD(stored=True, scorable=True),\n",
        "                       score=fields.NUMERIC(stored=True),\n",
        "                       review=fields.TEXT(stored=True),\n",
        "                       freshness=fields.KEYWORD(scorable=True))\n",
        "whoosh_parser = qparser.MultifieldParser(['movie_id', 'review'], schema=schema)\n",
        "try:\n",
        "    searcher = index.open_dir(DATAPATH + 'index').searcher(weighting=scoring.BM25F)\n",
        "except index.EmptyIndexError:\n",
        "    print(f'No index found in {DATAPATH} index')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqcdVEKpndX1"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-h9ViExqncXr"
      },
      "outputs": [],
      "source": [
        "def timeit(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        print(f'{func.__name__} took {round(time.time()-start)} seconds to complete')\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "def get_average_score(x, y, model, n=100):\n",
        "    rmses = []\n",
        "    maes = []\n",
        "    for _ in trange(n, leave=False, desc='running models'):\n",
        "        x_train, x_test, y_train, y_test = tts(x, y, test_size=0.1)\n",
        "        model.fit(x_train, y_train)\n",
        "        predictions = model.predict(x_test)\n",
        "        rmses.append(math.sqrt(mse(y_test, predictions)))\n",
        "        maes.append(mae(y_test, predictions))\n",
        "    rmses = np.array(rmses)\n",
        "    maes = np.array(maes)\n",
        "    print(f'getting average metrics on {n} {type(model).__name__}s')\n",
        "    print(f'avg RMSE: {round(rmses.mean(), 4)}, std: {round(np.std(rmses), 3)}')\n",
        "    print(f'avg MAE:  {round(maes.mean(), 4)}, std: {round(np.std(maes), 3)}')\n",
        "    return rmses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQUXH_2AoglW"
      },
      "source": [
        "## Model configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxNGC8qlob-J",
        "outputId": "a1c706b8-2583-467e-d815-fc2ff8dcef98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: stsb-roberta-large\n",
            "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cuda\n"
          ]
        }
      ],
      "source": [
        "model_features = ['cf_score',\n",
        "                  'difference',\n",
        "                  'dot_product',\n",
        "                  'meta_genre',\n",
        "                  'meta_people',\n",
        "                  'meta_description',\n",
        "                  'meta_title',\n",
        "                  'meta_runtime',\n",
        "                  'meta_date',\n",
        "                  'meta_audience_score',\n",
        "                  'meta_critics_score',\n",
        "                  'meta_amount_critics',\n",
        "                  'meta_amount_users']\n",
        "\n",
        "num_bert_feats = 1024\n",
        "bc = SentenceTransformer('stsb-roberta-large') \n",
        "cf_model = 'ncf'\n",
        "outpath = DATAPATH + '/model_artifacts/sentiment/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4mewhD6OrNq"
      },
      "source": [
        "## Loading files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEQVwwVtztsf"
      },
      "outputs": [],
      "source": [
        "conversations = json.load(open(DATAPATH + 'MovieSent.json', 'r'))\n",
        "movie_ids = json.load(open(DATAPATH + 'films_rt_ids.json', 'r'))\n",
        "movies_features = json.load(open(DATAPATH + 'films_features.json', 'r'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwOLUb_0Ox-J"
      },
      "source": [
        "## creating indexes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSeK51JQzygs"
      },
      "outputs": [],
      "source": [
        "@timeit\n",
        "def indexing(df, index_name=DATAPATH + 'index'):\n",
        "    os.makedirs(index_name, exist_ok=True)\n",
        "    ix = index.create_in(index_name, schema)\n",
        "    writer = ix.writer()\n",
        "    print('Indexing reviews')\n",
        "    for _, review in tqdm(df.iterrows(), total=df.shape[0], desc='adding reviews into index'):\n",
        "        writer.add_document(\n",
        "            movie_id=review['movie_id'],\n",
        "            critic_id=review['critic_id'],\n",
        "            review=review['review'],\n",
        "            score=review['score'])\n",
        "    print('Committing reviews. This will take a while')\n",
        "    writer.commit()\n",
        "    \n",
        "df = pd.read_table(DATAPATH + 'reviews.tsv')\n",
        "if CREATE_INDEX:\n",
        "  indexing(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ethttBR4O12T"
      },
      "source": [
        "## Data engineering and cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUHcW_P7H73T"
      },
      "outputs": [],
      "source": [
        "def entities_in_utterance(utterance):\n",
        "    \"\"\" extract entities from the utterance \"\"\"\n",
        "    if 'segments' not in utterance:\n",
        "        return set()\n",
        "    ents = set()\n",
        "    for segment in utterance['segments']:\n",
        "        entity_type = 'entityType' in segment['annotations'][0] and segment['annotations'][0]['entityType'] == 'MOVIE_OR_SERIES'\n",
        "        annotation_type = 'annotationType' in segment['annotations'][0] and segment['annotations'][0]['annotationType'] == 'ENTITY_NAME'\n",
        "        if entity_type and annotation_type:\n",
        "            if 'entityId' in segment['annotations'][0]:\n",
        "                ents.add(segment['annotations'][0]['entityId'])\n",
        "            else:\n",
        "                ents.add(segment['text'])\n",
        "    return ents\n",
        "\n",
        "\n",
        "def merge_utts(utterances):\n",
        "    \"\"\" merge utterances from the same speaker that apper in a row \"\"\"\n",
        "    cur_agent = utterances[0]['speaker']\n",
        "    result = ''\n",
        "    for utterance in utterances:\n",
        "        if utterance['speaker'] == cur_agent:\n",
        "            result += ' ' + utterance['text']\n",
        "        else:\n",
        "            result += ' ||| ' + utterance['text']\n",
        "            cur_agent = utterance['speaker']\n",
        "    return result.strip()\n",
        "\n",
        "\n",
        "def get_sentiment_from_utterance(utterance):\n",
        "    \"\"\" get the judge sentiment for the first entity in the utterance \"\"\"\n",
        "    for segment in utterance['segments']:\n",
        "        if 'annotations' in segment and 'sentiment' in segment['annotations'][0]:\n",
        "            intial_sentiment = segment['annotations'][0]['sentiment']\n",
        "            if np.isnan(intial_sentiment[0]):\n",
        "                return intial_sentiment[-1]\n",
        "            elif np.isnan(intial_sentiment[-1]):\n",
        "                return intial_sentiment[0]\n",
        "            return sum(intial_sentiment) / len(intial_sentiment)\n",
        "    print('sentiment not extracted from:', utterance)\n",
        "\n",
        "\n",
        "def sentiment_2_score(x):\n",
        "    \"\"\" convert [-3:+3] score to a [1:5] rating \"\"\"\n",
        "    try:\n",
        "        return round((2 * x + 9) / 3)\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "\n",
        "def get_gbdt_conversations(conversations):\n",
        "    \"\"\" convert original json conversations into pandas df\n",
        "        and add estimated score\n",
        "    \"\"\"\n",
        "    zero_reviewed = []\n",
        "    for movie_id in movie_ids:\n",
        "        results = searcher.search(whoosh_parser.parse(f'movie_id:{movie_id}'), limit=None)\n",
        "        if len(results) == 0:\n",
        "            zero_reviewed.append(movie_id)\n",
        "\n",
        "    list_of_lines = []\n",
        "    for conversation in conversations:\n",
        "        entities = set()\n",
        "        line = {'critic_id': conversation['conversationId']}\n",
        "        for utterance in conversation['utterances']:\n",
        "            cur_ents = entities_in_utterance(utterance)\n",
        "            if utterance['speaker'] == 'USER' and 'segments' in utterance and len(cur_ents) == 1:\n",
        "                movie_id = list(cur_ents)[0]\n",
        "                movie_sentiment = sentiment_2_score(get_sentiment_from_utterance(utterance))\n",
        "                valid_id = movie_id not in entities and movie_id not in zero_reviewed and movie_id in movie_ids\n",
        "                valid_score = len(entities) < 2 or not np.isnan(movie_sentiment)\n",
        "                if valid_id and valid_score:\n",
        "                    if len(entities) == 0:\n",
        "                        line['first movie_id'] = movie_id\n",
        "                        line['first score'] = movie_sentiment\n",
        "                        line['first text'] = get_context(conversation, utterance)\n",
        "                    elif len(entities) == 1:\n",
        "                        line['second movie_id'] = movie_id\n",
        "                        line['second score'] = movie_sentiment\n",
        "                        line['second text'] = get_context(conversation, utterance)\n",
        "                        line['review'] = merge_utts(conversation['utterances'][:utterance['index'] + 1])\n",
        "                    elif len(entities) == 2:\n",
        "                        line['target movie_id'] = movie_id\n",
        "                        line['target score'] = movie_sentiment\n",
        "                        list_of_lines.append(line)\n",
        "                        break\n",
        "                    entities.add(movie_id)\n",
        "    return pd.DataFrame.from_records(list_of_lines)\n",
        "\n",
        "\n",
        "def get_context(conversation, utterance):\n",
        "    if utterance['index'] > 0 and conversation['utterances'][utterance['index'] - 1]['speaker'] == 'ASSISTANT':\n",
        "        text = conversation['utterances'][utterance['index'] - 1]['text'] + ' ||| ' + utterance['text']\n",
        "    else:\n",
        "        text = utterance['text']\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FiHwBeAO5Pq"
      },
      "source": [
        "## Training sentiment model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziYc98MHH7wC"
      },
      "outputs": [],
      "source": [
        "def create_sentiment_trainset(file):\n",
        "    \"\"\" use utterances from conversations that can't be used\n",
        "        for the final model to train sentiment estimator on them\n",
        "    \"\"\"\n",
        "    forbidden_pairs = []\n",
        "    for column in ['first movie_id', 'second movie_id', 'target movie_id']:\n",
        "        forbidden_pairs += [list(i) for i in df_conv[['critic_id', column]].values]\n",
        "\n",
        "    list_of_lines = []\n",
        "    for conversation in conversations:\n",
        "        for utterance in conversation['utterances']:\n",
        "            line = {'critic_id': conversation['conversationId']}\n",
        "            cur_ents = entities_in_utterance(utterance)\n",
        "            if utterance['speaker'] == 'USER' and 'segments' in utterance and len(cur_ents) == 1:\n",
        "                movie_id = list(cur_ents)[0]\n",
        "                movie_sentiment = sentiment_2_score(get_sentiment_from_utterance(utterance))\n",
        "                if [conversation['conversationId'], movie_id] not in forbidden_pairs and not np.isnan(movie_sentiment):\n",
        "                    line['movie_id'] = movie_id\n",
        "                    line['score'] = movie_sentiment\n",
        "                    line['text'] = get_context(conversation, utterance)\n",
        "                    list_of_lines.append(line)\n",
        "    trainset = pd.DataFrame.from_records(list_of_lines)\n",
        "    trainset[['text', 'score']].to_csv(file, sep='\\t', index=False)\n",
        "\n",
        "\n",
        "@timeit\n",
        "def train_estimator(sentiment_df):\n",
        "\n",
        "    # embed the train dataset\n",
        "    emb_path = outpath + 'trainset_embeddings.txt'\n",
        "    if REGENERATE or not os.path.exists(model_path):\n",
        "        print('Calculating embeddings')\n",
        "        sentiment_estimation_embeddings = bc.encode(sentiment_df['text'].to_list())\n",
        "        print('Embeddings calculated')\n",
        "        np.savetxt(emb_path, sentiment_estimation_embeddings)\n",
        "    sentiment_estimation_embeddings = np.loadtxt(emb_path)\n",
        "\n",
        "    # remove those few conversations which have score 3 to reduce noise\n",
        "    indexes = sentiment_df[sentiment_df['score'] == 3].index.to_list()\n",
        "    sentiment_df = sentiment_df[sentiment_df['score'] != 3]\n",
        "    sentiment_estimation_embeddings = [i for ind, i in enumerate(sentiment_estimation_embeddings) if ind not in indexes]\n",
        "\n",
        "    print('Fitting the estimator')\n",
        "    x_train, x_test, y_train, y_test = tts(sentiment_estimation_embeddings, sentiment_df['score'], test_size=0.1)\n",
        "    model = RFR(n_estimators=500, max_depth=10, n_jobs=-1)\n",
        "    model.fit(x_train, y_train)\n",
        "    print('Estimator fitted')\n",
        "\n",
        "    pickle.dump(model, open(model_path, 'wb'))\n",
        "    y_pred = model.predict(x_test)\n",
        "    print(f'sentiment estimator RMSE: {round(math.sqrt(mse(y_test, y_pred)), 3)}')\n",
        "    print(f'sentiment estimator  MAE: {round(mae(y_test, y_pred), 3)}')\n",
        "    print(f'sentiment estimator  R^2: {round(model.score(x_test, y_test), 3)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tTxdPfPzSIO",
        "outputId": "0072cb64-9db2-401a-fee4-7fc27d3066aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculating embeddings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 21/21 [00:03<00:00,  6.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings calculated\n",
            "Fitting the estimator\n",
            "Estimator fitted\n",
            "sentiment estimator RMSE: 0.686\n",
            "sentiment estimator  MAE: 0.527\n",
            "sentiment estimator  R^2: 0.758\n",
            "train_estimator took 16 seconds to complete\n",
            "Encoding conversations\n",
            "Encoding done\n"
          ]
        }
      ],
      "source": [
        "df_conv = get_gbdt_conversations(conversations)\n",
        "model_path = outpath + 'estimator.pickle'\n",
        "trainset_path = outpath + 'trainset.tsv'\n",
        "\n",
        "os.makedirs(outpath, exist_ok=True)\n",
        "if REGENERATE or not os.path.exists(model_path):\n",
        "    if REGENERATE or not os.path.exists(trainset_path):\n",
        "        create_sentiment_trainset(trainset_path)\n",
        "    sentiment_df = pd.read_table(trainset_path)\n",
        "    train_estimator(sentiment_df)\n",
        "model = pickle.load(open(model_path, 'rb'))\n",
        "\n",
        "print('Encoding conversations')\n",
        "embeddings = bc.encode(df_conv['first text'].tolist() + df_conv['second text'].tolist(), show_progress_bar=False)\n",
        "df_conv['first score'] = model.predict(embeddings[:df_conv.shape[0]])\n",
        "df_conv['second score'] = model.predict(embeddings[df_conv.shape[0]:])\n",
        "print('Encoding done')\n",
        "\n",
        "df_conv.drop(['first text', 'second text'], axis=1, inplace=True)\n",
        "df_conv.to_csv(outpath + '/conversations_estimated.tsv', sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQxUEN2TO7uw"
      },
      "source": [
        "## Training CF model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cfYb9wVII3c"
      },
      "outputs": [],
      "source": [
        "def get_ranked_critics(movie_id, text):\n",
        "    ''' returns dict of ranked according to text critics with BM25 weights '''\n",
        "    query = whoosh_parser.parse(f'movie_id:{movie_id} AND (review:' + ' OR review:'.join(text.split()) + ')')\n",
        "    initial_list = [(i['critic_id'], i.score) for i in searcher.search(query, limit=None)]\n",
        "    if len(initial_list) > 0:\n",
        "        biggest_weight = initial_list[0][1]\n",
        "        return {i[0]: i[1] / biggest_weight for i in initial_list}\n",
        "    print(f'found 0 bm25 reviews for {movie_id}')\n",
        "    return {}\n",
        "\n",
        "\n",
        "def get_movie_critic_representation(row):\n",
        "    '''\n",
        "        returns movie vector, created using embeddings\n",
        "        of critics' reviews' and their BM25 weights\n",
        "    '''\n",
        "    critics_dict = get_ranked_critics(row.movie_id, row.review)\n",
        "    subdf = critics_reviews[critics_reviews['movie_id'] == row.movie_id]\n",
        "    subsubdf = subdf[subdf['critic_id'].isin(critics_dict.keys())]\n",
        "    if len(critics_dict) > 0:\n",
        "        encodings = bc.encode(subsubdf['review'].to_list(), show_progress_bar=False)\n",
        "        weights = [critics_dict[name] for name in subsubdf['critic_id'].to_list()]\n",
        "        weights = np.array(weights).reshape((len(weights), 1))\n",
        "        return (encodings * weights).mean(axis=0)\n",
        "    return np.zeros(num_bert_feats)\n",
        "\n",
        "\n",
        "@timeit\n",
        "def train_cf(df, model):\n",
        "    reader = Reader(rating_scale=(1, 5))\n",
        "    print('training ' + model)\n",
        "    if model == 'knn':\n",
        "        algo = KNNBaseline(sim_options={'name': 'cosine', 'user_based': True}, verbose=False)\n",
        "    elif model == 'svd':\n",
        "        algo = SVD(n_factors=500)\n",
        "    elif model == 'svdpp':\n",
        "        algo = SVDpp(n_factors=500)\n",
        "    data_train = Dataset.load_from_df(df, reader)\n",
        "    algo.fit(data_train.build_full_trainset())\n",
        "    pickle.dump(algo, open(outpath + f'cf_{model}.pkl', 'wb'))\n",
        "    \n",
        "def convert_to_cf_matrix(df):\n",
        "    ''' converts df_users into a standard records cf matrix '''\n",
        "    result = pd.DataFrame()\n",
        "    for number in ['first', 'second']:\n",
        "        temp = df[['critic_id', number + ' movie_id', number + ' score']].drop_duplicates()\n",
        "        temp = temp.rename(columns={number + ' movie_id': 'movie_id', number + ' score': 'score'})\n",
        "        result = result.append(temp)\n",
        "    return result\n",
        "            \n",
        "\n",
        "def get_cf_feature(df, model, REGENERATE):\n",
        "    if model == 'knn' or model == 'svd' or model == 'svdpp':\n",
        "        if not os.path.exists(outpath + f'cf_{model}.pkl') or REGENERATE:\n",
        "            df_users_cf = convert_to_cf_matrix(df)\n",
        "            df_cf = critics_reviews[['critic_id', 'movie_id', 'score']].append(df_users_cf).reset_index(drop=True).dropna()\n",
        "            train_cf(df_cf, model)\n",
        "        cf = pickle.load(open(outpath + f'cf_{model}.pkl', 'rb'))\n",
        "        df['cf_score'] = df.apply(lambda x: cf.predict(x['critic_id'], x['target movie_id']).est, axis=1)\n",
        "\n",
        "    elif model == 'ncf':\n",
        "        df_users_cf = convert_to_cf_matrix(df)\n",
        "        df_cf = critics_reviews[['critic_id', 'movie_id', 'score']].append(df_users_cf).reset_index(drop=True).dropna()\n",
        "        train_file = 'ncf_train.csv'\n",
        "        critic_ids, critic_id_map = pd.factorize(df_cf['critic_id'])\n",
        "        df_cf['critic_id'] = critic_ids\n",
        "        movie_ids, movie_id_map = pd.factorize(df_cf['movie_id'])\n",
        "        df_cf['movie_id'] = movie_ids\n",
        "        df_cf = df_cf.sort_values(by=['critic_id'])\n",
        "        df_cf.to_csv(train_file, index=False)\n",
        "        data_train = NCFDataset(train_file=train_file, col_user='critic_id', col_item='movie_id', col_rating='score')\n",
        "        algo = NCF (\n",
        "                n_users=data_train.n_users, \n",
        "                n_items=data_train.n_items,\n",
        "                model_type=\"GMF\",\n",
        "                n_factors=4,\n",
        "                layer_sizes=[16,8,4],\n",
        "                n_epochs=10,\n",
        "                batch_size=32,\n",
        "                learning_rate=1e-3,\n",
        "                verbose=10,\n",
        "                seed=42\n",
        "            )\n",
        "        algo.fit(data_train)\n",
        "        algo.save(dir_name=outpath+'/gmf')\n",
        "        algo = NCF (\n",
        "                n_users=data_train.n_users, \n",
        "                n_items=data_train.n_items,\n",
        "                model_type=\"MLP\",\n",
        "                n_factors=4,\n",
        "                layer_sizes=[16,8,4],\n",
        "                n_epochs=10,\n",
        "                batch_size=32,\n",
        "                learning_rate=1e-3,\n",
        "                verbose=10,\n",
        "                seed=42\n",
        "            )\n",
        "        algo.fit(data_train)\n",
        "        algo.save(dir_name=outpath+'/mlp')\n",
        "        algo = NCF (\n",
        "                n_users=data_train.n_users, \n",
        "                n_items=data_train.n_items,\n",
        "                model_type=\"NeuMF\",\n",
        "                n_factors=4,\n",
        "                layer_sizes=[16,8,4],\n",
        "                n_epochs=10,\n",
        "                batch_size=32,\n",
        "                learning_rate=1e-3,\n",
        "                verbose=10,\n",
        "                seed=42\n",
        "            )\n",
        "        algo.load(gmf_dir =outpath+\"/gmf\", mlp_dir=outpath+\"/mlp\", alpha=0.5)\n",
        "        algo.fit(data_train)\n",
        "        df['cf_score'] = df.apply(lambda x: algo.predict(np.where(x['critic_id'] == critic_id_map)[0][0], np.where(x['target movie_id'] == movie_id_map)[0][0]), axis=1)\n",
        "\n",
        "    print(f\"RMSE for CF: {math.sqrt(mse(df['cf_score'], df['target score']))}\")\n",
        "    print(f\" MAE for CF: {mae(df['cf_score'], df['target score'])}\")\n",
        "    df.to_csv(outpath + 'conversations_w_cf.tsv', sep='\\t', index=False)\n",
        "\n",
        "@timeit\n",
        "def get_users_emb(df, each_turn='full_text'):\n",
        "    '''\n",
        "        options for embedding calculation:\n",
        "            each_turn: takes the average embedding of turns' embeddings\n",
        "            full_text: takes the embedding of all text concatenated\n",
        "    '''\n",
        "    print('getting user embedding')\n",
        "    columns = [f'user_{i}' for i in range(num_bert_feats)]\n",
        "    if each_turn == 'each_turn':\n",
        "        embedded = [bc.encode(i, show_progress_bar=False).mean(axis=0) for i in df['review'].progress_apply(lambda x: x.split(' ||| ')).to_list()]\n",
        "        user_emb = pd.DataFrame.from_records(embedded, columns=columns)\n",
        "    else:\n",
        "        user_emb = pd.DataFrame.from_records(bc.encode(df['review'].to_list(), show_progress_bar=False), columns=columns)\n",
        "    user_emb.to_csv(outpath + f'users_emb_{each_turn}.tsv', sep='\\t', index=False)\n",
        "\n",
        "\n",
        "@timeit\n",
        "def get_critics_emb(df):\n",
        "    print('getting critic embedding')\n",
        "    tqdm_pandas.pandas(desc='critics_emb')\n",
        "    df_tmp = df.rename(columns={'target movie_id': 'movie_id'}).reset_index(drop=True)\n",
        "    df_tmp = df_tmp.progress_apply(get_movie_critic_representation, axis=1)\n",
        "    critics_emb = pd.DataFrame.from_records(df_tmp, columns=[f'critics_emb_{i}' for i in range(num_bert_feats)])\n",
        "    critics_emb.to_csv(outpath + 'critics_emb.tsv', sep='\\t', index=False)\n",
        "\n",
        "\n",
        "@timeit\n",
        "def get_metadata_features(df, user_vectors):\n",
        "    print('getting metadata features')\n",
        "    new_feats = []\n",
        "    for i, user in enumerate(tqdm(user_vectors, desc='metadata features')):\n",
        "        row = df.iloc[i].copy()\n",
        "        current_movie_features = movies_features[row['target movie_id']]\n",
        "        for feature in ['genre', 'people', 'description', 'title']:\n",
        "            if feature not in current_movie_features or current_movie_features[feature] == []:\n",
        "                print(f\"no {feature} for {row['target movie_id']}\")\n",
        "        if 'audience_score' not in current_movie_features or 'critic_score' not in current_movie_features:\n",
        "            print('no scores for ', row['target movie_id'])\n",
        "            row['meta_audience_score'] = np.nan\n",
        "            row['meta_critics_score'] = np.nan\n",
        "        else:\n",
        "            row['meta_audience_score'] = current_movie_features['audience_score'] / 100\n",
        "            row['meta_critics_score'] = current_movie_features['critic_score'] / 100\n",
        "\n",
        "        to_encode = [', '.join(current_movie_features['genre']),\n",
        "                     ', '.join(current_movie_features['people'][:10]),\n",
        "                     current_movie_features['description'],\n",
        "                     current_movie_features['title']]\n",
        "        for i in range(len(to_encode)):\n",
        "            if len(to_encode[i]) == 0:\n",
        "                to_encode[i] = 'None'\n",
        "        genre_vector, people_vector, descr_vector, title_vector = bc.encode(to_encode, show_progress_bar=False)\n",
        "\n",
        "        row['meta_date'] = current_movie_features['in theaters']\n",
        "        row['meta_runtime'] = current_movie_features['runtime']\n",
        "        row['meta_amount_critics'] = current_movie_features['amount of critics']\n",
        "        row['meta_amount_users'] = current_movie_features['amount of users']\n",
        "        row['meta_genre'] = np.dot(user, np.transpose(genre_vector))\n",
        "        row['meta_people'] = np.dot(user, np.transpose(people_vector))\n",
        "        row['meta_description'] = np.dot(user, np.transpose(descr_vector))\n",
        "        row['meta_title'] = np.dot(user, np.transpose(title_vector))\n",
        "        new_feats.append(row)\n",
        "    return pd.DataFrame.from_records(new_feats)\n",
        "\n",
        "\n",
        "def get_all_features(df_users, model, regenerate=False):\n",
        "    \"\"\" prepare a dataframe with all the features \"\"\"\n",
        "\n",
        "    print('generating data')\n",
        "    if not os.path.exists(outpath + 'conversations_w_cf.tsv') or regenerate:\n",
        "        get_cf_feature(df_users, model, regenerate)\n",
        "    if not os.path.exists(outpath + 'users_emb_full_text.tsv') or regenerate:\n",
        "        get_users_emb(df_users)\n",
        "    if not os.path.exists(outpath + 'critics_emb.tsv') or regenerate:\n",
        "        get_critics_emb(df_users)\n",
        "\n",
        "    df_users = pd.read_table(outpath + 'conversations_w_cf.tsv')\n",
        "    user_vectors = pd.read_table(outpath + 'users_emb_full_text.tsv').values.tolist()\n",
        "    critics_vectors = pd.read_table(outpath + 'critics_emb.tsv').values.tolist()\n",
        "\n",
        "    earth_movers_distance = [[stats.wasserstein_distance(critics_vectors[i], user)] for i, user in enumerate(user_vectors)]\n",
        "    dot_product = [[np.dot(user, np.transpose(critics_vectors[i]))] for i, user in enumerate(user_vectors)]\n",
        "    emd_df = pd.DataFrame.from_records(earth_movers_distance, columns=['difference'])\n",
        "    dp_df = pd.DataFrame.from_records(dot_product, columns=['dot_product'])\n",
        "\n",
        "    df_users = pd.concat([df_users.reset_index(drop=True), emd_df, dp_df], axis=1)\n",
        "    df_all_features = get_metadata_features(df_users, user_vectors)\n",
        "    df_all_features.to_csv(df_all_features_path, sep='\\t', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va-pZf8iO_Fk"
      },
      "source": [
        "## GBRT/Final recommender model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TpQ9VOTzK6w",
        "outputId": "60344a06-1ff7-4435-a4c1-05fdcfad363b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:recommenders.models.ncf.dataset:Indexing ncf_train.csv ...\n",
            "2022-05-10 18:08:57.869451: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8425 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:1a:00.0, compute capability: 8.6\n",
            "2022-05-10 18:08:57.870506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13004 MB memory:  -> device: 1, name: NVIDIA RTX A4000, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
            "2022-05-10 18:08:57.871476: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 11375 MB memory:  -> device: 2, name: NVIDIA RTX A4000, pci bus id: 0000:60:00.0, compute capability: 8.6\n",
            "2022-05-10 18:08:57.872181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 129 MB memory:  -> device: 3, name: NVIDIA RTX A4000, pci bus id: 0000:b1:00.0, compute capability: 8.6\n",
            "2022-05-10 18:08:57.872941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 1913 MB memory:  -> device: 4, name: NVIDIA RTX A4000, pci bus id: 0000:da:00.0, compute capability: 8.6\n",
            "2022-05-10 18:08:57.873741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 3963 MB memory:  -> device: 5, name: NVIDIA RTX A4000, pci bus id: 0000:db:00.0, compute capability: 8.6\n",
            "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 10 [412.63s]: train_loss = 0.283011 \n",
            "2022-05-10 19:15:02.799274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8425 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:1a:00.0, compute capability: 8.6\n",
            "2022-05-10 19:15:02.800333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13004 MB memory:  -> device: 1, name: NVIDIA RTX A4000, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
            "2022-05-10 19:15:02.801292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 11375 MB memory:  -> device: 2, name: NVIDIA RTX A4000, pci bus id: 0000:60:00.0, compute capability: 8.6\n",
            "2022-05-10 19:15:02.801983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 129 MB memory:  -> device: 3, name: NVIDIA RTX A4000, pci bus id: 0000:b1:00.0, compute capability: 8.6\n",
            "2022-05-10 19:15:02.802739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 1913 MB memory:  -> device: 4, name: NVIDIA RTX A4000, pci bus id: 0000:da:00.0, compute capability: 8.6\n",
            "2022-05-10 19:15:02.803541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 3963 MB memory:  -> device: 5, name: NVIDIA RTX A4000, pci bus id: 0000:db:00.0, compute capability: 8.6\n",
            "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 10 [404.85s]: train_loss = 0.692958 \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /common/users/jrp328/data//model_artifacts/sentiment//gmf/model.ckpt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-05-10 20:29:30.078176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8425 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:1a:00.0, compute capability: 8.6\n",
            "2022-05-10 20:29:30.079252: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13004 MB memory:  -> device: 1, name: NVIDIA RTX A4000, pci bus id: 0000:1b:00.0, compute capability: 8.6\n",
            "2022-05-10 20:29:30.080220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 11375 MB memory:  -> device: 2, name: NVIDIA RTX A4000, pci bus id: 0000:60:00.0, compute capability: 8.6\n",
            "2022-05-10 20:29:30.080915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 129 MB memory:  -> device: 3, name: NVIDIA RTX A4000, pci bus id: 0000:b1:00.0, compute capability: 8.6\n",
            "2022-05-10 20:29:30.081663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 1913 MB memory:  -> device: 4, name: NVIDIA RTX A4000, pci bus id: 0000:da:00.0, compute capability: 8.6\n",
            "2022-05-10 20:29:30.082448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 3963 MB memory:  -> device: 5, name: NVIDIA RTX A4000, pci bus id: 0000:db:00.0, compute capability: 8.6\n",
            "INFO:tensorflow:Restoring parameters from /common/users/jrp328/data//model_artifacts/sentiment//gmf/model.ckpt\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /common/users/jrp328/data//model_artifacts/sentiment//mlp/model.ckpt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /common/users/jrp328/data//model_artifacts/sentiment//mlp/model.ckpt\n",
            "INFO:recommenders.models.ncf.ncf_singlenode:Epoch 10 [523.92s]: train_loss = 0.265442 \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE for CF: 3.3684147712322123\n",
            " MAE for CF: 3.1627368382730725\n",
            "getting user embedding\n",
            "get_users_emb took 2 seconds to complete\n",
            "getting critic embedding\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "critics_emb: 100%|██████████| 236/236 [04:25<00:00,  1.13s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "get_critics_emb took 267 seconds to complete\n",
            "getting metadata features\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "metadata features:  69%|██████▉   | 163/236 [00:07<00:02, 26.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no people for star_wars_episode_vii_the_force_awakens\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "metadata features: 100%|██████████| 236/236 [00:10<00:00, 21.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "get_metadata_features took 11 seconds to complete\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getting average metrics on 10 GradientBoostingRegressors\n",
            "avg RMSE: 1.2747, std: 0.187\n",
            "avg MAE:  0.9583, std: 0.189\n",
            "RMSE: 1.2320972426235879\n",
            " MAE: 0.956936994872342\n",
            "Feature importances:\n",
            "0.1609 meta_critics_score\n",
            "0.137 dot_product\n",
            "0.1072 difference\n",
            "0.1023 meta_amount_critics\n",
            "0.0984 meta_description\n",
            "0.089 meta_people\n",
            "0.0786 cf_score\n",
            "0.0701 meta_genre\n",
            "0.0593 meta_audience_score\n",
            "0.0462 meta_title\n",
            "0.037 meta_amount_users\n",
            "0.0085 meta_date\n",
            "0.0055 meta_runtime\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getting average metrics on 20 GradientBoostingRegressors\n",
            "avg RMSE: 1.3238, std: 0.17\n",
            "avg MAE:  1.0145, std: 0.146\n",
            "RMSE: 1.392793021473241\n",
            " MAE: 1.0704963740728275\n",
            "Feature importances:\n",
            "0.1604 meta_critics_score\n",
            "0.1316 dot_product\n",
            "0.1106 difference\n",
            "0.11 meta_amount_critics\n",
            "0.0929 meta_description\n",
            "0.0836 cf_score\n",
            "0.0786 meta_people\n",
            "0.075 meta_genre\n",
            "0.0585 meta_audience_score\n",
            "0.0429 meta_title\n",
            "0.0287 meta_amount_users\n",
            "0.0163 meta_date\n",
            "0.0109 meta_runtime\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getting average metrics on 30 GradientBoostingRegressors\n",
            "avg RMSE: 1.3504, std: 0.163\n",
            "avg MAE:  1.0339, std: 0.147\n",
            "RMSE: 1.4310411884016554\n",
            " MAE: 1.081935881773723\n",
            "Feature importances:\n",
            "0.1595 meta_critics_score\n",
            "0.1307 dot_product\n",
            "0.116 meta_amount_critics\n",
            "0.1119 difference\n",
            "0.0938 meta_description\n",
            "0.0824 cf_score\n",
            "0.0822 meta_people\n",
            "0.0664 meta_genre\n",
            "0.0587 meta_audience_score\n",
            "0.0426 meta_title\n",
            "0.0326 meta_amount_users\n",
            "0.012 meta_runtime\n",
            "0.0113 meta_date\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getting average metrics on 40 GradientBoostingRegressors\n",
            "avg RMSE: 1.4054, std: 0.203\n",
            "avg MAE:  1.0771, std: 0.187\n",
            "RMSE: 1.3907629121838092\n",
            " MAE: 1.0622675588402875\n",
            "Feature importances:\n",
            "0.1667 meta_critics_score\n",
            "0.1293 dot_product\n",
            "0.1108 meta_amount_critics\n",
            "0.105 difference\n",
            "0.0948 meta_genre\n",
            "0.0845 meta_people\n",
            "0.0822 cf_score\n",
            "0.0682 meta_description\n",
            "0.057 meta_audience_score\n",
            "0.0465 meta_title\n",
            "0.0327 meta_amount_users\n",
            "0.0117 meta_runtime\n",
            "0.0107 meta_date\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getting average metrics on 50 GradientBoostingRegressors\n",
            "avg RMSE: 1.4106, std: 0.199\n",
            "avg MAE:  1.0767, std: 0.178\n",
            "RMSE: 1.456210419929647\n",
            " MAE: 1.125259393223244\n",
            "Feature importances:\n",
            "0.1583 meta_critics_score\n",
            "0.1312 dot_product\n",
            "0.11 meta_amount_critics\n",
            "0.1063 difference\n",
            "0.091 meta_genre\n",
            "0.0848 meta_people\n",
            "0.0841 cf_score\n",
            "0.077 meta_description\n",
            "0.0594 meta_audience_score\n",
            "0.0442 meta_title\n",
            "0.0279 meta_amount_users\n",
            "0.014 meta_date\n",
            "0.0117 meta_runtime\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getting average metrics on 60 GradientBoostingRegressors\n",
            "avg RMSE: 1.3575, std: 0.181\n",
            "avg MAE:  1.0456, std: 0.158\n",
            "RMSE: 1.4593400744523164\n",
            " MAE: 1.106907441155555\n",
            "Feature importances:\n",
            "0.1607 meta_critics_score\n",
            "0.128 dot_product\n",
            "0.1184 meta_amount_critics\n",
            "0.1076 difference\n",
            "0.1058 meta_description\n",
            "0.0811 cf_score\n",
            "0.0764 meta_people\n",
            "0.0627 meta_genre\n",
            "0.0588 meta_audience_score\n",
            "0.0438 meta_title\n",
            "0.0331 meta_amount_users\n",
            "0.0118 meta_runtime\n",
            "0.0118 meta_date\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getting average metrics on 70 GradientBoostingRegressors\n",
            "avg RMSE: 1.4296, std: 0.23\n",
            "avg MAE:  1.1006, std: 0.194\n",
            "RMSE: 1.4368372681144552\n",
            " MAE: 1.1063454740674026\n",
            "Feature importances:\n",
            "0.1604 meta_critics_score\n",
            "0.1298 dot_product\n",
            "0.112 difference\n",
            "0.1083 meta_amount_critics\n",
            "0.0911 meta_genre\n",
            "0.084 cf_score\n",
            "0.0808 meta_people\n",
            "0.0797 meta_description\n",
            "0.0582 meta_audience_score\n",
            "0.0407 meta_title\n",
            "0.0325 meta_amount_users\n",
            "0.012 meta_runtime\n",
            "0.0105 meta_date\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getting average metrics on 80 GradientBoostingRegressors\n",
            "avg RMSE: 1.377, std: 0.222\n",
            "avg MAE:  1.0627, std: 0.201\n",
            "RMSE: 1.4315346313446995\n",
            " MAE: 1.0927213571580847\n",
            "Feature importances:\n",
            "0.1591 meta_critics_score\n",
            "0.1366 dot_product\n",
            "0.111 difference\n",
            "0.1059 meta_amount_critics\n",
            "0.0862 meta_genre\n",
            "0.0821 cf_score\n",
            "0.0814 meta_people\n",
            "0.0777 meta_description\n",
            "0.0575 meta_audience_score\n",
            "0.0474 meta_title\n",
            "0.0285 meta_amount_users\n",
            "0.0146 meta_date\n",
            "0.012 meta_runtime\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getting average metrics on 90 GradientBoostingRegressors\n",
            "avg RMSE: 1.3973, std: 0.214\n",
            "avg MAE:  1.0625, std: 0.177\n",
            "RMSE: 1.4254934043671508\n",
            " MAE: 1.0875141206162946\n",
            "Feature importances:\n",
            "0.1616 meta_critics_score\n",
            "0.1334 dot_product\n",
            "0.1124 meta_amount_critics\n",
            "0.1087 difference\n",
            "0.0894 meta_genre\n",
            "0.0843 meta_people\n",
            "0.0838 cf_score\n",
            "0.0659 meta_description\n",
            "0.0563 meta_audience_score\n",
            "0.0472 meta_title\n",
            "0.0335 meta_amount_users\n",
            "0.0121 meta_date\n",
            "0.0112 meta_runtime\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getting average metrics on 100 GradientBoostingRegressors\n",
            "avg RMSE: 1.3632, std: 0.193\n",
            "avg MAE:  1.041, std: 0.173\n",
            "RMSE: 1.425271516432077\n",
            " MAE: 1.0820570674840448\n",
            "Feature importances:\n",
            "0.1592 meta_critics_score\n",
            "0.13 dot_product\n",
            "0.1074 difference\n",
            "0.1067 meta_amount_critics\n",
            "0.091 meta_genre\n",
            "0.0818 meta_people\n",
            "0.0815 cf_score\n",
            "0.0812 meta_description\n",
            "0.0573 meta_audience_score\n",
            "0.0455 meta_title\n",
            "0.0358 meta_amount_users\n",
            "0.0114 meta_runtime\n",
            "0.0111 meta_date\n"
          ]
        }
      ],
      "source": [
        "critics_reviews = pd.read_table(DATAPATH + 'reviews.tsv').drop(['fresh'], axis=1).dropna()\n",
        "\n",
        "df_users = pd.read_table(outpath + 'conversations_estimated.tsv')\n",
        "df_users = df_users[df_users['target movie_id'].isin(movies_features)]\n",
        "\n",
        "df_all_features_path = outpath + 'conversations_w_features.tsv'\n",
        "if not os.path.exists(df_all_features_path) or REGENERATE:\n",
        "    get_all_features(df_users, cf_model, REGENERATE)\n",
        "df_all_features = pd.read_table(df_all_features_path)\n",
        "\n",
        "rmse_res, mae_res = [], []\n",
        "for n_est in range(10, 101, 10): \n",
        "  # for tree_depth in [5, 7, 9, 11, 20]:\n",
        "  model = GBRT(n_estimators=n_est, max_depth=11)\n",
        "  X, y = df_all_features[model_features + ['target movie_id']], df_all_features['target score']\n",
        "  get_average_score(X.drop('target movie_id', axis=1), y, model, n=n_est)\n",
        "  X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=42)\n",
        "  model.fit(X_train.drop('target movie_id', axis=1), y_train)\n",
        "  y_pred = model.predict(X_test.drop('target movie_id', axis=1))\n",
        "  rmse_res.append(math.sqrt(mse(y_test, y_pred)))\n",
        "  mae_res.append(mae(y_test, y_pred))\n",
        "  print(f'RMSE: {rmse_res[-1]}')\n",
        "  print(f' MAE: {mae_res[-1]}')\n",
        "  pickle.dump(model, open(outpath + 'gbdt_final' + str(n_est) + '.pkl', 'wb'))\n",
        "  print('Feature importances:')\n",
        "  for score, feature in sorted(zip(model.feature_importances_, model_features), reverse=True):\n",
        "    print(f'{round(score, 4)} {feature}')\n",
        "pickle.dump(rmse_res, open(outpath + 'rmse_res' + '.pkl', 'wb'))\n",
        "pickle.dump(mae_res, open(outpath + 'mae_res' + '.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "6me6O9T8ORxg",
        "outputId": "3d7dd986-388a-44f7-b985-2d36c202ce6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fa983814580>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.title('Evaluation metrics for ' + cf_model)\n",
        "plt.xlabel('Number of GBRT estimators')\n",
        "plt.plot(range(10, 101, 10), rmse_res, label='RMSE')\n",
        "plt.plot(range(10, 101, 10), mae_res, label='MAE')\n",
        "plt.legend()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RnOkaub7pBh9",
        "p4mewhD6OrNq",
        "nwOLUb_0Ox-J"
      ],
      "name": "NLP_Project(1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}